---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a first-year PhD student at the [Institute for AI Industry Research (AIR)](https://air.tsinghua.edu.cn), Tsinghua University, fortunately advised by Prof.[ Jingjing Liu](https://air.tsinghua.edu.cn/info/1046/1201.htm) (aka JJ) and [Prof. Hao Zhou](https://zhouh.github.io). I also closely collaborate with Prof.[Yang Liu](https://air.tsinghua.edu.cn/info/1046/1204.htm) and Prof.[Yang Liu](https://air.tsinghua.edu.cn/info/1046/1198.htm).

My research interest lies in self-supervised learning, multimodal large foundation models.

## Research Persuit

I am devoting all myself to pursue the birth of safe *super intelligence*. Only after this goal is achieved can I truly retire :).

~~*big convergence of language, vision and multimodal learning*, to help machines comprehensively understand the fanscinating world, like human. (also well known as, **AGI**)~~

## Internships

2023.01 -- Now, Beijing Academy of Artificial Intelligence (BAAI), metored by [Yue Cao](http://yue-cao.me), [Quan Sun](https://github.com/Quan-Sun) and [Xinlong Wang](https://www.xloong.wang).

## Publications

\* Equal Contribution

### Preprint

Quan Sun\*, **Qiying Yu**\*, Yufeng Cui\*, Fan Zhang\*, Xiaosong Zhang\*, Yueze Wang, Hongcheng Gao, Jingjing Liu, Tiejun Huang, Xinlong Wang. [Generative Pretraining in Multimodality](https://arxiv.org/abs/2307.05222). [[code](https://github.com/baaivision/Emu)]

### Conference

**Qiying Yu**, Yimu Wang, Ke Xu, Yang Liu, Jingjing Liu. [Multimodal Federated Learning via Contrastive Representation Ensemble](https://openreview.net/pdf?id=Hnk1WRMAYqg). ICLR 2023. [[code](https://github.com/FLAIR-THU/CreamFL)]

**Qiying Yu**, Jieming Lou, Xianyuan Zhan, Qizhang Li, Wangmeng Zuo, Yang Liu and Jingjing Liu. [Adversarial Contrastive Learning via Asymmetric InfoNCE](https://arxiv.org/abs/2207.08374). ECCV 2022. [[code](https://github.com/yqy2001/A-InfoNCE)]

## Projects

### [OpenChat: Advancing Open-source Language Models with Imperfect Data](https://github.com/imoneoi/openchat) 

* **OpenChat v1 ranks #1 among all open-source models (Vicuna, Alpaca, UltraLM, etc) on Stanford's [AlpacaEval](https://tatsu-lab.github.io/alpaca_eval/)**
* **OpenChat v2 outperforms ChatGPT on [AlpacaEval](https://tatsu-lab.github.io/alpaca_eval/)**

## Inspirational Persons:

Below are some persons from around the world whom I **greatly admire**:

[Andrej Karpathy](https://karpathy.ai/), [Mu Li](http://www.cs.cmu.edu/~muli/index.html): They have had a profound impact on me with their incredible open-source spirit.

Ilya Sutskever, Sam Altman.
